{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import WhisperProcessor, TFWhisperForConditionalGeneration\n",
    "from time import time\n",
    "from os import path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-04 14:22:27.951417: W tensorflow/tsl/framework/bfc_allocator.cc:485] Allocator (GPU_0_bfc) ran out of memory trying to allocate 937.8KiB (rounded to 960512)requested by op Pad\n",
      "If the cause is memory fragmentation maybe the environment variable 'TF_GPU_ALLOCATOR=cuda_malloc_async' will improve the situation. \n",
      "Current allocation summary follows.\n",
      "Current allocation summary follows.\n",
      "2023-09-04 14:22:27.951446: I tensorflow/tsl/framework/bfc_allocator.cc:1039] BFCAllocator dump for GPU_0_bfc\n",
      "2023-09-04 14:22:27.951456: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (256): \tTotal Chunks: 19, Chunks in use: 19. 4.8KiB allocated for chunks. 4.8KiB in use in bin. 80B client-requested in use in bin.\n",
      "2023-09-04 14:22:27.951463: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (512): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-09-04 14:22:27.951470: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (1024): \tTotal Chunks: 1, Chunks in use: 1. 1.2KiB allocated for chunks. 1.2KiB in use in bin. 1.0KiB client-requested in use in bin.\n",
      "2023-09-04 14:22:27.951477: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (2048): \tTotal Chunks: 3, Chunks in use: 3. 6.0KiB allocated for chunks. 6.0KiB in use in bin. 6.0KiB client-requested in use in bin.\n",
      "2023-09-04 14:22:27.951484: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (4096): \tTotal Chunks: 6, Chunks in use: 6. 27.2KiB allocated for chunks. 27.2KiB in use in bin. 24.0KiB client-requested in use in bin.\n",
      "2023-09-04 14:22:27.951491: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (8192): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-09-04 14:22:27.951497: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (16384): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-09-04 14:22:27.951503: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (32768): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-09-04 14:22:27.951509: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (65536): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-09-04 14:22:27.951515: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (131072): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-09-04 14:22:27.951522: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (262144): \tTotal Chunks: 3, Chunks in use: 2. 1.40MiB allocated for chunks. 960.0KiB in use in bin. 960.0KiB client-requested in use in bin.\n",
      "2023-09-04 14:22:27.951529: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (524288): \tTotal Chunks: 14, Chunks in use: 12. 12.70MiB allocated for chunks. 11.05MiB in use in bin. 10.56MiB client-requested in use in bin.\n",
      "2023-09-04 14:22:27.951536: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (1048576): \tTotal Chunks: 1, Chunks in use: 1. 1.28MiB allocated for chunks. 1.28MiB in use in bin. 937.2KiB client-requested in use in bin.\n",
      "2023-09-04 14:22:27.951542: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (2097152): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-09-04 14:22:27.951548: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (4194304): \tTotal Chunks: 11, Chunks in use: 11. 59.44MiB allocated for chunks. 59.44MiB in use in bin. 58.88MiB client-requested in use in bin.\n",
      "2023-09-04 14:22:27.951555: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (8388608): \tTotal Chunks: 1, Chunks in use: 1. 12.00MiB allocated for chunks. 12.00MiB in use in bin. 12.00MiB client-requested in use in bin.\n",
      "2023-09-04 14:22:27.951561: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (16777216): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-09-04 14:22:27.951567: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (33554432): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-09-04 14:22:27.951573: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (67108864): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-09-04 14:22:27.951583: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (134217728): \tTotal Chunks: 1, Chunks in use: 1. 142.08MiB allocated for chunks. 142.08MiB in use in bin. 137.33MiB client-requested in use in bin.\n",
      "2023-09-04 14:22:27.951589: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (268435456): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-09-04 14:22:27.951596: I tensorflow/tsl/framework/bfc_allocator.cc:1062] Bin for 938.0KiB was 512.0KiB, Chunk State: \n",
      "2023-09-04 14:22:27.951607: I tensorflow/tsl/framework/bfc_allocator.cc:1068]   Size: 780.5KiB | Requested Size: 480.0KiB | in_use: 0 | bin_num: 11, prev:   Size: 480.0KiB | Requested Size: 480.0KiB | in_use: 1 | bin_num: -1, next:   Size: 4.00MiB | Requested Size: 4.00MiB | in_use: 1 | bin_num: -1\n",
      "2023-09-04 14:22:27.951616: I tensorflow/tsl/framework/bfc_allocator.cc:1068]   Size: 903.5KiB | Requested Size: 480.0KiB | in_use: 0 | bin_num: 11, prev:   Size: 2.0KiB | Requested Size: 2.0KiB | in_use: 1 | bin_num: -1, next:   Size: 938.0KiB | Requested Size: 937.8KiB | in_use: 1 | bin_num: -1\n",
      "2023-09-04 14:22:27.951622: I tensorflow/tsl/framework/bfc_allocator.cc:1075] Next region of size 240058368\n",
      "2023-09-04 14:22:27.951630: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f4f18000000 of size 256 next 1\n",
      "2023-09-04 14:22:27.951635: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f4f18000100 of size 1280 next 2\n",
      "2023-09-04 14:22:27.951640: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f4f18000600 of size 959744 next 3\n",
      "2023-09-04 14:22:27.951645: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f4f180eab00 of size 256 next 6\n",
      "2023-09-04 14:22:27.951650: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f4f180eac00 of size 256 next 7\n",
      "2023-09-04 14:22:27.951654: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f4f180ead00 of size 256 next 10\n",
      "2023-09-04 14:22:27.951659: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f4f180eae00 of size 4096 next 8\n",
      "2023-09-04 14:22:27.951664: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f4f180ebe00 of size 256 next 14\n",
      "2023-09-04 14:22:27.951669: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f4f180ebf00 of size 256 next 15\n",
      "2023-09-04 14:22:27.951673: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f4f180ec000 of size 256 next 18\n",
      "2023-09-04 14:22:27.951678: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f4f180ec100 of size 256 next 16\n",
      "2023-09-04 14:22:27.951683: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f4f180ec200 of size 256 next 17\n",
      "2023-09-04 14:22:27.951688: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f4f180ec300 of size 4096 next 20\n",
      "2023-09-04 14:22:27.951692: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f4f180ed300 of size 256 next 9\n",
      "2023-09-04 14:22:27.951697: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f4f180ed400 of size 256 next 13\n",
      "2023-09-04 14:22:27.951702: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f4f180ed500 of size 256 next 25\n",
      "2023-09-04 14:22:27.951707: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f4f180ed600 of size 4096 next 24\n",
      "2023-09-04 14:22:27.951711: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f4f180ee600 of size 4096 next 28\n",
      "2023-09-04 14:22:27.951716: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f4f180ef600 of size 256 next 29\n",
      "2023-09-04 14:22:27.951721: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f4f180ef700 of size 256 next 34\n",
      "2023-09-04 14:22:27.951725: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f4f180ef800 of size 4096 next 36\n",
      "2023-09-04 14:22:27.951730: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f4f180f0800 of size 256 next 35\n",
      "2023-09-04 14:22:27.951735: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f4f180f0900 of size 7424 next 31\n",
      "2023-09-04 14:22:27.951741: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f4f180f2600 of size 256 next 30\n",
      "2023-09-04 14:22:27.951746: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f4f180f2700 of size 256 next 42\n",
      "2023-09-04 14:22:27.951750: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f4f180f2800 of size 256 next 47\n",
      "2023-09-04 14:22:27.951755: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f4f180f2900 of size 256 next 48\n",
      "2023-09-04 14:22:27.951760: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f4f180f2a00 of size 2048 next 50\n",
      "2023-09-04 14:22:27.951765: I tensorflow/tsl/framework/bfc_allocator.cc:1095] Free  at 7f4f180f3200 of size 925184 next 4\n",
      "2023-09-04 14:22:27.951770: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f4f181d5000 of size 960512 next 5\n",
      "2023-09-04 14:22:27.951776: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f4f182bf800 of size 960000 next 44\n",
      "2023-09-04 14:22:27.951781: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f4f183a9e00 of size 1006080 next 12\n",
      "2023-09-04 14:22:27.951787: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f4f1849f800 of size 983040 next 11\n",
      "2023-09-04 14:22:27.951792: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f4f1858f800 of size 6144000 next 19\n",
      "2023-09-04 14:22:27.951797: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f4f18b6b800 of size 6144000 next 27\n",
      "2023-09-04 14:22:27.951802: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f4f19147800 of size 6144000 next 26\n",
      "2023-09-04 14:22:27.951807: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f4f19723800 of size 960512 next 49\n",
      "2023-09-04 14:22:27.951811: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f4f1980e000 of size 959744 next 51\n",
      "2023-09-04 14:22:27.951816: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f4f198f8500 of size 959744 next 54\n",
      "2023-09-04 14:22:27.951821: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f4f199e2a00 of size 960512 next 57\n",
      "2023-09-04 14:22:27.951826: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f4f19acd200 of size 959744 next 59\n",
      "2023-09-04 14:22:27.951831: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f4f19bb7700 of size 1343744 next 33\n",
      "2023-09-04 14:22:27.951836: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f4f19cff800 of size 6148096 next 23\n",
      "2023-09-04 14:22:27.951841: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f4f1a2dc800 of size 6733824 next 22\n",
      "2023-09-04 14:22:27.951846: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f4f1a948800 of size 12582912 next 21\n",
      "2023-09-04 14:22:27.951851: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f4f1b548800 of size 6144000 next 32\n",
      "2023-09-04 14:22:27.951856: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f4f1bb24800 of size 4194304 next 37\n",
      "2023-09-04 14:22:27.951861: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f4f1bf24800 of size 959744 next 45\n",
      "2023-09-04 14:22:27.951866: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f4f1c00ed00 of size 960512 next 46\n",
      "2023-09-04 14:22:27.951871: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f4f1c0f9500 of size 491520 next 52\n",
      "2023-09-04 14:22:27.951876: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f4f1c171500 of size 2048 next 53\n",
      "2023-09-04 14:22:27.951884: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f4f1c171d00 of size 2048 next 58\n",
      "2023-09-04 14:22:27.951889: I tensorflow/tsl/framework/bfc_allocator.cc:1095] Free  at 7f4f1c172500 of size 487680 next 55\n",
      "2023-09-04 14:22:27.951894: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f4f1c1e9600 of size 491520 next 56\n",
      "2023-09-04 14:22:27.951899: I tensorflow/tsl/framework/bfc_allocator.cc:1095] Free  at 7f4f1c261600 of size 799232 next 41\n",
      "2023-09-04 14:22:27.951903: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f4f1c324800 of size 4194304 next 40\n",
      "2023-09-04 14:22:27.951907: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f4f1c724800 of size 6144000 next 38\n",
      "2023-09-04 14:22:27.951911: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f4f1cd00800 of size 4194304 next 43\n",
      "2023-09-04 14:22:27.951914: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f4f1d100800 of size 6144000 next 39\n",
      "2023-09-04 14:22:27.951918: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f4f1d6dc800 of size 148977664 next 18446744073709551615\n",
      "2023-09-04 14:22:27.951921: I tensorflow/tsl/framework/bfc_allocator.cc:1100]      Summary of in-use Chunks by size: \n",
      "2023-09-04 14:22:27.951926: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 19 Chunks of size 256 totalling 4.8KiB\n",
      "2023-09-04 14:22:27.951929: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 1280 totalling 1.2KiB\n",
      "2023-09-04 14:22:27.951932: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 3 Chunks of size 2048 totalling 6.0KiB\n",
      "2023-09-04 14:22:27.951935: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 5 Chunks of size 4096 totalling 20.0KiB\n",
      "2023-09-04 14:22:27.951939: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 7424 totalling 7.2KiB\n",
      "2023-09-04 14:22:27.951942: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 2 Chunks of size 491520 totalling 960.0KiB\n",
      "2023-09-04 14:22:27.951945: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 5 Chunks of size 959744 totalling 4.58MiB\n",
      "2023-09-04 14:22:27.951948: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 960000 totalling 937.5KiB\n",
      "2023-09-04 14:22:27.951952: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 4 Chunks of size 960512 totalling 3.66MiB\n",
      "2023-09-04 14:22:27.951955: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 983040 totalling 960.0KiB\n",
      "2023-09-04 14:22:27.951958: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 1006080 totalling 982.5KiB\n",
      "2023-09-04 14:22:27.951961: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 1343744 totalling 1.28MiB\n",
      "2023-09-04 14:22:27.951964: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 3 Chunks of size 4194304 totalling 12.00MiB\n",
      "2023-09-04 14:22:27.951968: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 6 Chunks of size 6144000 totalling 35.16MiB\n",
      "2023-09-04 14:22:27.951971: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 6148096 totalling 5.86MiB\n",
      "2023-09-04 14:22:27.951974: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 6733824 totalling 6.42MiB\n",
      "2023-09-04 14:22:27.951977: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 12582912 totalling 12.00MiB\n",
      "2023-09-04 14:22:27.951980: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 148977664 totalling 142.08MiB\n",
      "2023-09-04 14:22:27.951984: I tensorflow/tsl/framework/bfc_allocator.cc:1107] Sum Total of in-use chunks: 226.83MiB\n",
      "2023-09-04 14:22:27.951987: I tensorflow/tsl/framework/bfc_allocator.cc:1109] Total bytes in pool: 240058368 memory_limit_: 240058368 available bytes: 0 curr_region_allocation_bytes_: 480116736\n",
      "2023-09-04 14:22:27.951994: I tensorflow/tsl/framework/bfc_allocator.cc:1114] Stats: \n",
      "Limit:                       240058368\n",
      "InUse:                       237846272\n",
      "MaxInUse:                    239103488\n",
      "NumAllocs:                         182\n",
      "MaxAllocSize:                180598784\n",
      "Reserved:                            0\n",
      "PeakReserved:                        0\n",
      "LargestFreeBlock:                    0\n",
      "\n",
      "2023-09-04 14:22:27.952002: W tensorflow/tsl/framework/bfc_allocator.cc:497] **************************************************************************************************xx\n",
      "2023-09-04 14:22:27.952019: W tensorflow/core/framework/op_kernel.cc:1828] OP_REQUIRES failed at pad_op.cc:136 : RESOURCE_EXHAUSTED: OOM when allocating tensor with shape[1,3001,80] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "Exception encountered when calling layer 'encoder' (type TFWhisperEncoder).\n\n{{function_node __wrapped__Pad_device_/job:localhost/replica:0/task:0/device:GPU:0}} OOM when allocating tensor with shape[1,3001,80] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc [Op:Pad]\n\nCall arguments received by layer 'encoder' (type TFWhisperEncoder):\n  • input_features=tf.Tensor(shape=(1, 80, 2999), dtype=float32)\n  • head_mask=None\n  • output_attentions=False\n  • output_hidden_states=False\n  • return_dict=True\n  • training=False",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m start_time \u001b[39m=\u001b[39m time()\n\u001b[1;32m      2\u001b[0m processor \u001b[39m=\u001b[39m WhisperProcessor\u001b[39m.\u001b[39mfrom_pretrained(\u001b[39m\"\u001b[39m\u001b[39mopenai/whisper-base.en\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m model \u001b[39m=\u001b[39m TFWhisperForConditionalGeneration\u001b[39m.\u001b[39mfrom_pretrained(\u001b[39m\"\u001b[39m\u001b[39mopenai/whisper-base.en\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      5\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mTook \u001b[39m\u001b[39m{\u001b[39;00mtime()\u001b[39m \u001b[39m\u001b[39m-\u001b[39m\u001b[39m \u001b[39mstart_time\u001b[39m}\u001b[39;00m\u001b[39ms to load model.\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/project-ki/lib/python3.11/site-packages/transformers/modeling_tf_utils.py:2908\u001b[0m, in \u001b[0;36mTFPreTrainedModel.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   2906\u001b[0m         model\u001b[39m.\u001b[39mbuild()  \u001b[39m# build the network with dummy inputs\u001b[39;00m\n\u001b[1;32m   2907\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 2908\u001b[0m     model\u001b[39m.\u001b[39mbuild()  \u001b[39m# build the network with dummy inputs\u001b[39;00m\n\u001b[1;32m   2910\u001b[0m \u001b[39mif\u001b[39;00m safetensors_from_pt:\n\u001b[1;32m   2911\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mmodeling_tf_pytorch_utils\u001b[39;00m \u001b[39mimport\u001b[39;00m load_pytorch_state_dict_in_tf2_model\n",
      "File \u001b[0;32m~/miniconda3/envs/project-ki/lib/python3.11/site-packages/transformers/modeling_tf_utils.py:1138\u001b[0m, in \u001b[0;36mTFPreTrainedModel.build\u001b[0;34m(self, input_shape)\u001b[0m\n\u001b[1;32m   1135\u001b[0m \u001b[39m# Set the serving spec quickly to ensure that Keras doesn't use the specific dummy input shapes as the spec\u001b[39;00m\n\u001b[1;32m   1136\u001b[0m \u001b[39m# Setting it in build() allows users to override the shape when loading a non-pretrained model from config\u001b[39;00m\n\u001b[1;32m   1137\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_set_save_spec(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39minput_signature)\n\u001b[0;32m-> 1138\u001b[0m \u001b[39mself\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdummy_inputs, training\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/miniconda3/envs/project-ki/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/miniconda3/envs/project-ki/lib/python3.11/site-packages/transformers/modeling_tf_utils.py:426\u001b[0m, in \u001b[0;36munpack_inputs.<locals>.run_call_with_unpacked_inputs\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    423\u001b[0m     config \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\n\u001b[1;32m    425\u001b[0m unpacked_inputs \u001b[39m=\u001b[39m input_processing(func, config, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfn_args_and_kwargs)\n\u001b[0;32m--> 426\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39munpacked_inputs)\n",
      "File \u001b[0;32m~/miniconda3/envs/project-ki/lib/python3.11/site-packages/transformers/models/whisper/modeling_tf_whisper.py:1291\u001b[0m, in \u001b[0;36mTFWhisperForConditionalGeneration.call\u001b[0;34m(self, input_features, decoder_input_ids, decoder_attention_mask, decoder_position_ids, head_mask, decoder_head_mask, cross_attn_head_mask, encoder_outputs, past_key_values, decoder_inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict, training)\u001b[0m\n\u001b[1;32m   1286\u001b[0m     \u001b[39mif\u001b[39;00m decoder_input_ids \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m decoder_inputs_embeds \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   1287\u001b[0m         decoder_input_ids \u001b[39m=\u001b[39m shift_tokens_right(\n\u001b[1;32m   1288\u001b[0m             labels, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mpad_token_id, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mdecoder_start_token_id\n\u001b[1;32m   1289\u001b[0m         )\n\u001b[0;32m-> 1291\u001b[0m outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel(\n\u001b[1;32m   1292\u001b[0m     input_features,\n\u001b[1;32m   1293\u001b[0m     decoder_input_ids\u001b[39m=\u001b[39mdecoder_input_ids,\n\u001b[1;32m   1294\u001b[0m     encoder_outputs\u001b[39m=\u001b[39mencoder_outputs,\n\u001b[1;32m   1295\u001b[0m     decoder_attention_mask\u001b[39m=\u001b[39mdecoder_attention_mask,\n\u001b[1;32m   1296\u001b[0m     decoder_position_ids\u001b[39m=\u001b[39mdecoder_position_ids,\n\u001b[1;32m   1297\u001b[0m     head_mask\u001b[39m=\u001b[39mhead_mask,\n\u001b[1;32m   1298\u001b[0m     decoder_head_mask\u001b[39m=\u001b[39mdecoder_head_mask,\n\u001b[1;32m   1299\u001b[0m     cross_attn_head_mask\u001b[39m=\u001b[39mcross_attn_head_mask,\n\u001b[1;32m   1300\u001b[0m     past_key_values\u001b[39m=\u001b[39mpast_key_values,\n\u001b[1;32m   1301\u001b[0m     decoder_inputs_embeds\u001b[39m=\u001b[39mdecoder_inputs_embeds,\n\u001b[1;32m   1302\u001b[0m     use_cache\u001b[39m=\u001b[39muse_cache,\n\u001b[1;32m   1303\u001b[0m     output_attentions\u001b[39m=\u001b[39moutput_attentions,\n\u001b[1;32m   1304\u001b[0m     output_hidden_states\u001b[39m=\u001b[39moutput_hidden_states,\n\u001b[1;32m   1305\u001b[0m     return_dict\u001b[39m=\u001b[39mreturn_dict,\n\u001b[1;32m   1306\u001b[0m     training\u001b[39m=\u001b[39mtraining,\n\u001b[1;32m   1307\u001b[0m )\n\u001b[1;32m   1308\u001b[0m decoder_last_hidden_state \u001b[39m=\u001b[39m outputs[\u001b[39m0\u001b[39m]\n\u001b[1;32m   1309\u001b[0m \u001b[39m# Decoder and encoder embeddings are tied\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/project-ki/lib/python3.11/site-packages/transformers/modeling_tf_utils.py:426\u001b[0m, in \u001b[0;36munpack_inputs.<locals>.run_call_with_unpacked_inputs\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    423\u001b[0m     config \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\n\u001b[1;32m    425\u001b[0m unpacked_inputs \u001b[39m=\u001b[39m input_processing(func, config, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfn_args_and_kwargs)\n\u001b[0;32m--> 426\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39munpacked_inputs)\n",
      "File \u001b[0;32m~/miniconda3/envs/project-ki/lib/python3.11/site-packages/transformers/models/whisper/modeling_tf_whisper.py:1041\u001b[0m, in \u001b[0;36mTFWhisperMainLayer.call\u001b[0;34m(self, input_features, decoder_input_ids, decoder_attention_mask, decoder_position_ids, head_mask, decoder_head_mask, cross_attn_head_mask, encoder_outputs, past_key_values, decoder_inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict, training)\u001b[0m\n\u001b[1;32m   1038\u001b[0m return_dict \u001b[39m=\u001b[39m return_dict \u001b[39mif\u001b[39;00m return_dict \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39muse_return_dict\n\u001b[1;32m   1040\u001b[0m \u001b[39mif\u001b[39;00m encoder_outputs \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 1041\u001b[0m     encoder_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mencoder(\n\u001b[1;32m   1042\u001b[0m         input_features,\n\u001b[1;32m   1043\u001b[0m         head_mask\u001b[39m=\u001b[39mhead_mask,\n\u001b[1;32m   1044\u001b[0m         output_attentions\u001b[39m=\u001b[39moutput_attentions,\n\u001b[1;32m   1045\u001b[0m         output_hidden_states\u001b[39m=\u001b[39moutput_hidden_states,\n\u001b[1;32m   1046\u001b[0m         return_dict\u001b[39m=\u001b[39mreturn_dict,\n\u001b[1;32m   1047\u001b[0m         training\u001b[39m=\u001b[39mtraining,\n\u001b[1;32m   1048\u001b[0m     )\n\u001b[1;32m   1049\u001b[0m \u001b[39m# If the user passed a tuple for encoder_outputs, we wrap it in a TFBaseModelOutput when return_dict=True\u001b[39;00m\n\u001b[1;32m   1050\u001b[0m \u001b[39melif\u001b[39;00m return_dict \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(encoder_outputs, TFBaseModelOutput):\n",
      "File \u001b[0;32m~/miniconda3/envs/project-ki/lib/python3.11/site-packages/transformers/modeling_tf_utils.py:426\u001b[0m, in \u001b[0;36munpack_inputs.<locals>.run_call_with_unpacked_inputs\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    423\u001b[0m     config \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\n\u001b[1;32m    425\u001b[0m unpacked_inputs \u001b[39m=\u001b[39m input_processing(func, config, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfn_args_and_kwargs)\n\u001b[0;32m--> 426\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39munpacked_inputs)\n",
      "File \u001b[0;32m~/miniconda3/envs/project-ki/lib/python3.11/site-packages/transformers/models/whisper/modeling_tf_whisper.py:673\u001b[0m, in \u001b[0;36mTFWhisperEncoder.call\u001b[0;34m(self, input_features, head_mask, output_attentions, output_hidden_states, return_dict, training)\u001b[0m\n\u001b[1;32m    671\u001b[0m \u001b[39m# TF 2.0 layers can't use channels first format when running on CPU.\u001b[39;00m\n\u001b[1;32m    672\u001b[0m input_features \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mtranspose(input_features, perm\u001b[39m=\u001b[39m(\u001b[39m0\u001b[39m, \u001b[39m2\u001b[39m, \u001b[39m1\u001b[39m))\n\u001b[0;32m--> 673\u001b[0m input_features \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mpad(input_features, [[\u001b[39m0\u001b[39m, \u001b[39m0\u001b[39m], [\u001b[39m1\u001b[39m, \u001b[39m1\u001b[39m], [\u001b[39m0\u001b[39m, \u001b[39m0\u001b[39m]])\n\u001b[1;32m    674\u001b[0m inputs_embeds \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mactivations\u001b[39m.\u001b[39mgelu(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconv1(input_features))\n\u001b[1;32m    675\u001b[0m inputs_embeds \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mpad(inputs_embeds, [[\u001b[39m0\u001b[39m, \u001b[39m0\u001b[39m], [\u001b[39m1\u001b[39m, \u001b[39m1\u001b[39m], [\u001b[39m0\u001b[39m, \u001b[39m0\u001b[39m]])\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: Exception encountered when calling layer 'encoder' (type TFWhisperEncoder).\n\n{{function_node __wrapped__Pad_device_/job:localhost/replica:0/task:0/device:GPU:0}} OOM when allocating tensor with shape[1,3001,80] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc [Op:Pad]\n\nCall arguments received by layer 'encoder' (type TFWhisperEncoder):\n  • input_features=tf.Tensor(shape=(1, 80, 2999), dtype=float32)\n  • head_mask=None\n  • output_attentions=False\n  • output_hidden_states=False\n  • return_dict=True\n  • training=False"
     ]
    }
   ],
   "source": [
    "start_time = time()\n",
    "processor = WhisperProcessor.from_pretrained(\"openai/whisper-base.en\")\n",
    "model = TFWhisperForConditionalGeneration.from_pretrained(\"openai/whisper-base.en\")\n",
    "\n",
    "print(f\"Took {time() - start_time}s to load model.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 7\u001b[0m\n\u001b[1;32m      3\u001b[0m data \u001b[39m=\u001b[39m audio_functions\u001b[39m.\u001b[39mconvert_sample_rate(audio_functions\u001b[39m.\u001b[39mload_file(\u001b[39m\"\u001b[39m\u001b[39m./model_test.wav\u001b[39m\u001b[39m\"\u001b[39m), \u001b[39m16000\u001b[39m)\n\u001b[1;32m      5\u001b[0m features \u001b[39m=\u001b[39m processor(data, sampling_rate\u001b[39m=\u001b[39m\u001b[39m16000\u001b[39m, return_tensors\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mtf\u001b[39m\u001b[39m\"\u001b[39m)\u001b[39m.\u001b[39minput_features\n\u001b[0;32m----> 7\u001b[0m tokens \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mgenerate(features)\n\u001b[1;32m      9\u001b[0m output \u001b[39m=\u001b[39m processor\u001b[39m.\u001b[39mbatch_decode(tokens, skip_special_tokens\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m     11\u001b[0m output\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "import audio_functions\n",
    "\n",
    "data = audio_functions.convert_sample_rate(audio_functions.load_file(\"./model_test.wav\"), 16000)\n",
    "\n",
    "features = processor(data, sampling_rate=16000, return_tensors=\"tf\").input_features\n",
    "\n",
    "tokens = model.generate(features)\n",
    "\n",
    "output = processor.batch_decode(tokens, skip_special_tokens=True)\n",
    "\n",
    "output"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import WhisperProcessor, TFWhisperForConditionalGeneration\n",
    "from time import time\n",
    "from os import path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time()\n",
    "processor = WhisperProcessor.from_pretrained(\"openai/whisper-base.en\")\n",
    "model = TFWhisperForConditionalGeneration.from_pretrained(\"openai/whisper-base.en\")\n",
    "\n",
    "print(f\"Took {time() - start_time}s to load model.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import audio_functions\n",
    "\n",
    "data = audio_functions.convert_sample_rate(audio_functions.load_file(\"./model_test.wav\"), 16000)\n",
    "\n",
    "features = processor(data, sampling_rate=16000, return_tensors=\"tf\").input_features\n",
    "\n",
    "tokens = model.generate(features)\n",
    "\n",
    "output = processor.batch_decode(tokens, skip_special_tokens=True)\n",
    "\n",
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# testing audio generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "\nBarkModel requires the PyTorch library but it was not found in your environment.\nHowever, we were able to find a TensorFlow installation. TensorFlow classes begin\nwith \"TF\", but are otherwise identically named to our PyTorch classes. This\nmeans that the TF equivalent of the class you tried to import would be \"TFBarkModel\".\nIf you want to use TensorFlow, please use TF classes instead!\n\nIf you really do want to use PyTorch please go to\nhttps://pytorch.org/get-started/locally/ and follow the instructions that\nmatch your environment.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m/home/andrewli/c/project-ki/src/audio/test.ipynb Cell 5\u001b[0m line \u001b[0;36m4\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/andrewli/c/project-ki/src/audio/test.ipynb#W4sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtransformers\u001b[39;00m \u001b[39mimport\u001b[39;00m AutoProcessor, BarkModel\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/andrewli/c/project-ki/src/audio/test.ipynb#W4sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m processor \u001b[39m=\u001b[39m AutoProcessor\u001b[39m.\u001b[39mfrom_pretrained(\u001b[39m\"\u001b[39m\u001b[39msuno/bark-small\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/andrewli/c/project-ki/src/audio/test.ipynb#W4sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m model \u001b[39m=\u001b[39m BarkModel\u001b[39m.\u001b[39;49mfrom_pretrained(\u001b[39m\"\u001b[39m\u001b[39msuno/bark-small\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/andrewli/c/project-ki/src/audio/test.ipynb#W4sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m inputs \u001b[39m=\u001b[39m processor(text\u001b[39m=\u001b[39m[\u001b[39m\"\u001b[39m\u001b[39mhello, this is my audio message to be tested with the openai whisper large version 2 model.\u001b[39m\u001b[39m\"\u001b[39m], return_tensors\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mtf\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/andrewli/c/project-ki/src/audio/test.ipynb#W4sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m speech_values \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mgenerate(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39minputs, do_sample\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/miniconda3/envs/project-ki/lib/python3.11/site-packages/transformers/utils/import_utils.py:1070\u001b[0m, in \u001b[0;36mDummyObject.__getattribute__\u001b[0;34m(cls, key)\u001b[0m\n\u001b[1;32m   1068\u001b[0m \u001b[39mif\u001b[39;00m key\u001b[39m.\u001b[39mstartswith(\u001b[39m\"\u001b[39m\u001b[39m_\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mand\u001b[39;00m key \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m_from_config\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m   1069\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__getattribute__\u001b[39m(key)\n\u001b[0;32m-> 1070\u001b[0m requires_backends(\u001b[39mcls\u001b[39;49m, \u001b[39mcls\u001b[39;49m\u001b[39m.\u001b[39;49m_backends)\n",
      "File \u001b[0;32m~/miniconda3/envs/project-ki/lib/python3.11/site-packages/transformers/utils/import_utils.py:1049\u001b[0m, in \u001b[0;36mrequires_backends\u001b[0;34m(obj, backends)\u001b[0m\n\u001b[1;32m   1047\u001b[0m \u001b[39m# Raise an error for users who might not realize that classes without \"TF\" are torch-only\u001b[39;00m\n\u001b[1;32m   1048\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mtorch\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m backends \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mtf\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m backends \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m is_torch_available() \u001b[39mand\u001b[39;00m is_tf_available():\n\u001b[0;32m-> 1049\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mImportError\u001b[39;00m(PYTORCH_IMPORT_ERROR_WITH_TF\u001b[39m.\u001b[39mformat(name))\n\u001b[1;32m   1051\u001b[0m \u001b[39m# Raise the inverse error for PyTorch users trying to load TF classes\u001b[39;00m\n\u001b[1;32m   1052\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mtf\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m backends \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mtorch\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m backends \u001b[39mand\u001b[39;00m is_torch_available() \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m is_tf_available():\n",
      "\u001b[0;31mImportError\u001b[0m: \nBarkModel requires the PyTorch library but it was not found in your environment.\nHowever, we were able to find a TensorFlow installation. TensorFlow classes begin\nwith \"TF\", but are otherwise identically named to our PyTorch classes. This\nmeans that the TF equivalent of the class you tried to import would be \"TFBarkModel\".\nIf you want to use TensorFlow, please use TF classes instead!\n\nIf you really do want to use PyTorch please go to\nhttps://pytorch.org/get-started/locally/ and follow the instructions that\nmatch your environment.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoProcessor, BarkModel\n",
    "\n",
    "processor = AutoProcessor.from_pretrained(\"suno/bark-small\")\n",
    "model = BarkModel.from_pretrained(\"suno/bark-small\")\n",
    "inputs = processor(text=[\"hello, this is my audio message to be tested with the openai whisper large version 2 model.\"], return_tensors=\"tf\")\n",
    "\n",
    "speech_values = model.generate(**inputs, do_sample=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
